{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hotchpotch/miniconda3/envs/llm-sc/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import streamlit as st\n",
    "import os\n",
    "\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "from time import time\n",
    "from datasets.download import DownloadManager\n",
    "from datasets import load_dataset  # type: ignore\n",
    "import time\n",
    "from dataclasses import dataclass\n",
    "import json\n",
    "import urllib.request\n",
    "\n",
    "JAQKET_V1_DEV_URLS = [\n",
    "    \"https://jaqket.s3.ap-northeast-1.amazonaws.com/data/aio_01/dev1_questions.json\",\n",
    "    \"https://jaqket.s3.ap-northeast-1.amazonaws.com/data/aio_01/dev2_questions.json\",\n",
    "]\n",
    "\n",
    "\n",
    "WIKIPEDIA_JA_DS = \"singletongue/wikipedia-utils\"\n",
    "WIKIPEDIA_JS_DS_NAME = \"passages-c400-jawiki-20230403\"\n",
    "WIKIPEDIA_JA_EMB_DS = \"hotchpotch/wikipedia-passages-jawiki-embeddings\"\n",
    "\n",
    "EMB_MODEL_PQ = {\n",
    "    \"intfloat/multilingual-e5-small\": 96,\n",
    "    \"intfloat/multilingual-e5-base\": 192,\n",
    "    \"intfloat/multilingual-e5-large\": 256,\n",
    "    \"cl-nagoya/sup-simcse-ja-base\": 192,\n",
    "    \"pkshatech/GLuCoSE-base-ja\": 192,\n",
    "}\n",
    "\n",
    "EMB_MODEL_NAMES = list(EMB_MODEL_PQ.keys())\n",
    "\n",
    "E5_QUERY_TYPES = [\n",
    "    \"passage\",\n",
    "    \"query\",\n",
    "]\n",
    "\n",
    "# for tokenizer\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "\n",
    "def get_model(name: str, max_seq_length=512):\n",
    "    device = \"cpu\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda\"\n",
    "    elif torch.backends.mps.is_available():\n",
    "        device = \"mps\"\n",
    "    model = SentenceTransformer(name, device=device)\n",
    "    model.max_seq_length = max_seq_length\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_wikija_ds(name: str = WIKIPEDIA_JS_DS_NAME):\n",
    "    ds = load_dataset(path=WIKIPEDIA_JA_DS, name=name, split=\"train\")\n",
    "    return ds\n",
    "\n",
    "\n",
    "def get_faiss_index(\n",
    "    index_name: str, ja_emb_ds: str = WIKIPEDIA_JA_EMB_DS, name=WIKIPEDIA_JS_DS_NAME\n",
    "):\n",
    "    target_path = f\"faiss_indexes/{name}/{index_name}\"\n",
    "    dm = DownloadManager()\n",
    "    index_local_path = dm.download(\n",
    "        f\"https://huggingface.co/datasets/{ja_emb_ds}/resolve/main/{target_path}\"\n",
    "    )\n",
    "    index = faiss.read_index(index_local_path)\n",
    "    index.nprobe = 256\n",
    "    return index\n",
    "\n",
    "\n",
    "def texts_to_embs(model, texts: list[str], prefix: str):\n",
    "    texts = [prefix + text for text in texts]\n",
    "    embs = model.encode(texts, normalize_embeddings=True, show_progress_bar=True)\n",
    "    return embs\n",
    "\n",
    "\n",
    "def faiss_search_by_embs(faiss_index, embs, top_k=5):\n",
    "    start_time = time.time()\n",
    "    D, I = faiss_index.search(embs, top_k)\n",
    "    end_time = time.time()\n",
    "    print(f\"faiss search time: {end_time - start_time}\")\n",
    "    return D, I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jaqket v1\n",
    "@dataclass\n",
    "class JaqketQuestionV1:\n",
    "    qid: str\n",
    "    question: str\n",
    "    answer_entity: str\n",
    "    label: int\n",
    "    answer_candidates: list[str]\n",
    "    original_question: str\n",
    "\n",
    "\n",
    "def load_jaqket_v1_dev(urls):\n",
    "    res = []\n",
    "    for url in urls:\n",
    "        with urllib.request.urlopen(url) as f:\n",
    "            # f は 1行ごとに処理\n",
    "            data = [json.loads(line.decode(\"utf-8\")) for line in f]\n",
    "        for d in data:\n",
    "            # label position\n",
    "            d[\"label\"] = d[\"answer_candidates\"].index(d[\"answer_entity\"])\n",
    "            # if -1\n",
    "            if d[\"label\"] == -1:\n",
    "                raise ValueError(\n",
    "                    f\"answer_entity not found in answer_candidates: {d['answer_entity']}, {d['answer_candidates']}\"\n",
    "                )\n",
    "            res.append(JaqketQuestionV1(**d))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_model_name = \"intfloat/multilingual-e5-large\"\n",
    "e5_query_or_passage = \"passage\"\n",
    "top_k = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = get_wikija_ds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaqket_v1_dev = load_jaqket_v1_dev(JAQKET_V1_DEV_URLS)\n",
    "# jaqket_v1_dev = jaqket_v1_dev[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(emb_model_name)\n",
    "model.max_seq_length = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"-e5-\" in emb_model_name:\n",
    "    index_emb_model_name = f\"{emb_model_name.split('/')[-1]}-{e5_query_or_passage}\"\n",
    "    search_text_prefix = f\"query: \"  # 　検索するための prefix は元データが passage でも \"query: \" を指定する\n",
    "else:\n",
    "    index_emb_model_name = emb_model_name.split(\"/\")[-1]\n",
    "    search_text_prefix = \"\"\n",
    "\n",
    "emb_model_pq = EMB_MODEL_PQ[emb_model_name]\n",
    "index_name = f\"{index_emb_model_name}/index_IVF2048_PQ{emb_model_pq}.faiss\"\n",
    "faiss_index = get_faiss_index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 63/63 [00:02<00:00, 22.69it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1992, 1024)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_embs = texts_to_embs(\n",
    "    model, texts=[q.question for q in jaqket_v1_dev], prefix=search_text_prefix\n",
    ")\n",
    "question_embs.shape  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faiss search time: 9.45790147781372\n"
     ]
    }
   ],
   "source": [
    "scores, indexes = faiss_search_by_embs(faiss_index, question_embs, top_k=top_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_label_by_indexes(idxs, jaqket: JaqketQuestionV1, wiki_ds):\n",
    "    for idx in idxs:\n",
    "        data = wiki_ds[idx]\n",
    "        title = data[\"title\"]\n",
    "        # まずは title が jaqket の answer_candidates に完全一致するか\n",
    "        for j, candidate in enumerate(jaqket.answer_candidates):\n",
    "            if candidate == title:\n",
    "                return j\n",
    "        # XXX: RAG のユースケースを考えると、ここで続きも計算したほうが良い?\n",
    "\n",
    "    for idx in idxs:\n",
    "        data = wiki_ds[idx]\n",
    "        text = data[\"text\"]\n",
    "        # 次に text が jaqket の answer_candidates に含まれているか\n",
    "        for j, candidate in enumerate(jaqket.answer_candidates):\n",
    "            if candidate in text:\n",
    "                return j\n",
    "    return -1\n",
    "\n",
    "\n",
    "def predict_by_indexes(indexes, jaqket_ds, wiki_ds):\n",
    "    pred_labels = []\n",
    "    for idxs, jaqket in zip(indexes, jaqket_ds):\n",
    "        pred_label = find_label_by_indexes(idxs.tolist(), jaqket, wiki_ds)\n",
    "        pred_labels.append(pred_label)\n",
    "    return pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels = predict_by_indexes(indexes, jaqket_v1_dev, ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05973895582329317\n"
     ]
    }
   ],
   "source": [
    "# pred labels に含まれる、-1 の割合\n",
    "not_found_index_count = sum([1 for l in pred_labels if l == -1]) / len(pred_labels)\n",
    "print(not_found_index_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7484939759036144\n"
     ]
    }
   ],
   "source": [
    "# 正解率を表示\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "labels = [q.label for q in jaqket_v1_dev]\n",
    "print(accuracy_score(labels, pred_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
